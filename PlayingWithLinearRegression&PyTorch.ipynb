{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+VxOtDv9DCpgqzLCSfLlt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "myMHWs2yx2sd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import numpy as np\n",
        "from numpy.random import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zkJHzuJeyGnp",
        "outputId": "c49602ae-e874-4351-c18e-9d1b63acd6d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = random((30,2))\n",
        "y = np.dot(x,[2.,-3.]) +1.\n",
        "w_source = np.array([2.,-3.])\n",
        "b_source = np.array([1.])"
      ],
      "metadata": {
        "id": "GJ28O1IvyK2p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45rSwL013Hav",
        "outputId": "fca71d2c-34ca-423f-fea1-ebdd56c7d89f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03993043, 0.96609203],\n",
              "       [0.37884645, 0.87867106],\n",
              "       [0.89296698, 0.77253695],\n",
              "       [0.47642663, 0.19304256],\n",
              "       [0.05444117, 0.63777982]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "def plot_figs(fig_num,elev,azim,x,y,weights,bias):\n",
        "  fig = plt.figure(fig_num,figsize=(4,3))\n",
        "  plt.clf()\n",
        "  ax = Axes3D(fig,elev=elev,azim=azim)\n",
        "  ax.scatter(x[:,0],x[:,1],y)\n",
        "  ax.plot_surface(np.array([[0, 0], [1, 1]]),\n",
        "   np.array([[0, 1], [0, 1]]),\n",
        "   (np.dot(np.array([[0, 0, 1, 1],\n",
        "   [0, 1, 0, 1]]).T, weights) + bias).reshape((2, 2)),alpha=.5)\n",
        "  ax.set_xlabel('x_1')\n",
        "  ax.set_ylabel('x_2')\n",
        "  ax.set_zlabel('y')\n",
        "\n",
        "def plot_views(x,y,w,b):\n",
        "  elev = 43.5\n",
        "  azim = -110\n",
        "  plot_figs(1,elev,azim,x,y,w,b[0])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "XQDP1Z5-3Juh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_views(x,y,w_source,b_source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "B7YEXM9_3eWQ",
        "outputId": "1ae01768-92fc-4da7-ffd0-cfd720fa93f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_init = random(2)\n",
        "b_init = random(1)\n",
        "w = w_init\n",
        "b = b_init\n",
        "print('Initial values of the params',w,b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gDPsMeL5ITA",
        "outputId": "03327bdd-bdb0-4594-cfc9-36b529953033"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial values of the params [0.92316734 0.38644598] [0.73824242]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  return x.dot(w)+b\n",
        "def loss(x,y):\n",
        "  y_pred = forward(x)\n",
        "  return (y-y_pred)**2\n",
        "\n",
        "print('Initial Loss:',np.sum([loss(x_val,y_val) for x_val, y_val in zip(x,y)]))\n",
        "\n",
        "def gradient(x,y):\n",
        "  return 2*(x.dot(w)+b-y)*x,2*(x.dot(w)+b - y)\n",
        "\n",
        "lr = 1e-2\n",
        "\n",
        "for epoch in range(10):\n",
        "  grad_w = np.array([0,0])\n",
        "  grad_b = np.array([0])\n",
        "  l = 0\n",
        "  for x_val,y_val in zip(x,y):\n",
        "    grad_w = np.add(grad_w,gradient(x_val,y_val)[0])\n",
        "    grad_b = np.add(grad_b,gradient(x_val,y_val)[1])\n",
        "    l+=loss(x_val,y_val)\n",
        "  w = w - lr * grad_w\n",
        "  b = b - lr * grad_b\n",
        "  print('progress:','epoch:',epoch,'loss',l[0])\n",
        "\n",
        "print('Estimation of the params',w,b)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjiJW8sQ60Y6",
        "outputId": "96fcbea9-2d75-43a9-d4c3-da5a33e8c3c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Loss: 68.98904961765692\n",
            "progress: epoch: 0 loss 68.98904961765692\n",
            "progress: epoch: 1 loss 19.34984310403876\n",
            "progress: epoch: 2 loss 17.933526166905704\n",
            "progress: epoch: 3 loss 16.625258665006264\n",
            "progress: epoch: 4 loss 15.416520412530101\n",
            "progress: epoch: 5 loss 14.299489940717352\n",
            "progress: epoch: 6 loss 13.266975030967423\n",
            "progress: epoch: 7 loss 12.312361263416742\n",
            "progress: epoch: 8 loss 11.42956481827919\n",
            "progress: epoch: 9 loss 10.612989175938411\n",
            "Estimation of the params [ 1.12020646 -0.92426687] [0.1765857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_views(x,y,w,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Cblc2SUC-Lre",
        "outputId": "afda2e91-2bd4-4898-c86e-252231fdf922"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = torch.FloatTensor"
      ],
      "metadata": {
        "id": "u_Ij_RJk_6Xd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_t = torch.from_numpy(x).type(dtype)\n",
        "y_t = torch.from_numpy(y).type(dtype).unsqueeze(1)"
      ],
      "metadata": {
        "id": "DELCoFCxBMXx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_init_t = torch.from_numpy(w_init).type(dtype)\n",
        "b_init_t = torch.from_numpy(b_init).type(dtype)\n",
        "\n",
        "w_t = w_init_t.clone()\n",
        "w_t.unsqueeze_(1)\n",
        "b_t = b_init_t.clone()\n",
        "b_t.unsqueeze_(1)\n",
        "print('initial values of the params:',w_t,b_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5S9vrxoCGSb",
        "outputId": "b998829a-59ff-46eb-eb6e-a30be95d5cb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial values of the params: tensor([[0.9232],\n",
            "        [0.3864]]) tensor([[0.7382]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_t(x):\n",
        "  return x.mm(w_t)+b_t\n",
        "\n",
        "def loss_t(x,y):\n",
        "  y_pred = x.mm(w_t)+b_t\n",
        "  return (y_pred-y).pow(2).sum()\n",
        "\n",
        "def gradient_t(x,y):\n",
        "  return 2*torch.mm(torch.t(x),x.mm(w_t)+b_t-y),2*(x.mm(w_t)+b_t-y).sum()\n",
        "\n",
        "lr = 1e-2\n",
        "for epoch in range(10):\n",
        "  l_t = loss_t(x_t,y_t)\n",
        "  grad_w,grad_b = gradient_t(x_t,y_t)\n",
        "  w_t = w_t - lr*grad_w\n",
        "  b_t = b_t - lr*grad_b\n",
        "  print('Progress:','Epoch:',epoch,'Loss',l_t.item())\n",
        "\n",
        "print('Estimation of the params',w,b)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbO4sHGnCG79",
        "outputId": "007a9ce4-aab8-43e4-89bc-b7dac3578fc0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: Epoch: 0 Loss 4.783901214599609\n",
            "Progress: Epoch: 1 Loss 4.457211494445801\n",
            "Progress: Epoch: 2 Loss 4.154014587402344\n",
            "Progress: Epoch: 3 Loss 3.8725438117980957\n",
            "Progress: Epoch: 4 Loss 3.6111700534820557\n",
            "Progress: Epoch: 5 Loss 3.368391275405884\n",
            "Progress: Epoch: 6 Loss 3.142822265625\n",
            "Progress: Epoch: 7 Loss 2.9331836700439453\n",
            "Progress: Epoch: 8 Loss 2.738295078277588\n",
            "Progress: Epoch: 9 Loss 2.5570693016052246\n",
            "Estimation of the params [ 1.12020646 -0.92426687] [0.1765857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression with Autograd"
      ],
      "metadata": {
        "id": "r0hJkRa9KUsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_v = w_init_t.clone().unsqueeze(1)\n",
        "w_v.requires_grad_(True)\n",
        "b_v  = b_init_t.clone().unsqueeze(1)\n",
        "b_v.requires_grad_(True)\n",
        "print('Initial values of the params',w_v.data,b_v.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1n6Hbp4G49e",
        "outputId": "6276b1ff-c7ab-4b13-b140-89b08bd567b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial values of the params tensor([[0.9232],\n",
            "        [0.3864]]) tensor([[0.7382]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  y_pred = x_t.mm(w_v)+b_v\n",
        "  loss = (y_pred - y_t).pow(2).sum()\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w_v -= lr * w_v.grad\n",
        "    b_v -= lr* b_v.grad\n",
        "\n",
        "  w_v.grad.zero_()\n",
        "  b_v.grad.zero_()\n",
        "\n",
        "  print('Progress:','Epoch:',epoch,'loss',loss.data.item())\n",
        "\n",
        "print(\"estimation of the parameters:\", w_v.data, b_v.data.t() )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2eo3fOyK50b",
        "outputId": "16fd74a1-d493-4d89-83f3-a49c0ab49549"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: Epoch: 0 loss 68.98905181884766\n",
            "Progress: Epoch: 1 loss 19.349842071533203\n",
            "Progress: Epoch: 2 loss 17.93352699279785\n",
            "Progress: Epoch: 3 loss 16.625259399414062\n",
            "Progress: Epoch: 4 loss 15.416521072387695\n",
            "Progress: Epoch: 5 loss 14.299488067626953\n",
            "Progress: Epoch: 6 loss 13.266973495483398\n",
            "Progress: Epoch: 7 loss 12.312360763549805\n",
            "Progress: Epoch: 8 loss 11.429563522338867\n",
            "Progress: Epoch: 9 loss 10.612988471984863\n",
            "estimation of the parameters: tensor([[ 1.1202],\n",
            "        [-0.9243]]) tensor([[0.1766]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression with Neural Network"
      ],
      "metadata": {
        "id": "5ZsZOoDkMy53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(torch.nn.Linear(2,1),)\n",
        "for m in model.children():\n",
        "  m.weight.data = w_init_t.clone().unsqueeze(0)\n",
        "  m.bias.data = b_init_t.clone()\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "  y_pred = model(x_t)\n",
        "  loss = loss_fn(y_pred,y_t)\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    for param in model.parameters():\n",
        "      param.data -= lr*param.grad\n",
        "  print('Progress','Epoch',epoch,'Loss',loss.data.item())\n",
        "\n",
        "print(\"Estimation of the params:\")\n",
        "for param in model.parameters():\n",
        "  print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH3jZj7FMi0q",
        "outputId": "256bbf3a-e247-41f3-8026-79b112ecd164"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress Epoch 0 Loss 68.98905181884766\n",
            "Progress Epoch 1 Loss 19.349842071533203\n",
            "Progress Epoch 2 Loss 17.93352699279785\n",
            "Progress Epoch 3 Loss 16.625259399414062\n",
            "Progress Epoch 4 Loss 15.416521072387695\n",
            "Progress Epoch 5 Loss 14.299488067626953\n",
            "Progress Epoch 6 Loss 13.266973495483398\n",
            "Progress Epoch 7 Loss 12.312360763549805\n",
            "Progress Epoch 8 Loss 11.429563522338867\n",
            "Progress Epoch 9 Loss 10.612988471984863\n",
            "Estimation of the params:\n",
            "Parameter containing:\n",
            "tensor([[ 1.1202, -0.9243]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1766], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Optim package to update the weights and bias"
      ],
      "metadata": {
        "id": "M1vU5D4QRU_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(torch.nn.Linear(2,1),)\n",
        "for m in model.children():\n",
        "  m.weight.data = w_init_t.clone().unsqueeze(0)\n",
        "  m.bias.data = b_init_t.clone()\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "model.train()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
        "\n",
        "for epoch in range(10):\n",
        "  y_pred = model(x_t)\n",
        "  loss = loss_fn(y_pred,y_t)\n",
        "  print('Progress:','Epoch:',epoch,'Loss',loss.item())\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print('Estimation of the params')\n",
        "for param in model.parameters():\n",
        "  print(param)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzZPgCePOMdo",
        "outputId": "ce481b29-86b7-4680-d6c9-616968e63735"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: Epoch: 0 Loss 68.98905181884766\n",
            "Progress: Epoch: 1 Loss 19.349842071533203\n",
            "Progress: Epoch: 2 Loss 17.93352699279785\n",
            "Progress: Epoch: 3 Loss 16.625259399414062\n",
            "Progress: Epoch: 4 Loss 15.416521072387695\n",
            "Progress: Epoch: 5 Loss 14.299489974975586\n",
            "Progress: Epoch: 6 Loss 13.266973495483398\n",
            "Progress: Epoch: 7 Loss 12.312360763549805\n",
            "Progress: Epoch: 8 Loss 11.429563522338867\n",
            "Progress: Epoch: 9 Loss 10.612988471984863\n",
            "Estimation of the params\n",
            "Parameter containing:\n",
            "tensor([[ 1.1202, -0.9243]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1766], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solving Linear Regression algebrically"
      ],
      "metadata": {
        "id": "xbMN2a9-TRxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xb_t = torch.cat((x_t,torch.ones(30).unsqueeze(1)),1)\n",
        "sol = torch.linalg.lstsq(xb_t,y_t)\n",
        "sol.solution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v09spb6vTIrq",
        "outputId": "d771502e-e684-4457-de02-90df3071196d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.0000],\n",
              "        [-3.0000],\n",
              "        [ 1.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise"
      ],
      "metadata": {
        "id": "K95S4lV2V7cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = random((300,2))\n",
        "y = np.dot(x,[2.,-3.]) + 1\n",
        "x_t = torch.from_numpy(x).type(dtype)\n",
        "y_t = torch.from_numpy(y).type(dtype).unsqueeze(1)"
      ],
      "metadata": {
        "id": "olio6Y56T0Ow"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001"
      ],
      "metadata": {
        "id": "GI_CrcpFVr9i"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(torch.nn.Linear(2,1),)\n",
        "for m in model.children():\n",
        "  m.weight.data = w_init_t.clone().unsqueeze(0)\n",
        "  m.bias.data = b_init_t.clone()\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction = 'sum')\n",
        "\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x_t)\n",
        "    loss = loss_fn(y_pred, y_t)\n",
        "    print(\"progress:\", \"epoch:\", epoch, \"loss\",loss.item())\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "# After training\n",
        "print(\"estimation of the parameters:\")\n",
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzHM0wK4U57s",
        "outputId": "94f272b9-ce56-4411-d248-70be328364f3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress: epoch: 0 loss 606.6519775390625\n",
            "progress: epoch: 1 loss 249.57183837890625\n",
            "progress: epoch: 2 loss 225.75772094726562\n",
            "progress: epoch: 3 loss 205.57424926757812\n",
            "progress: epoch: 4 loss 187.21250915527344\n",
            "progress: epoch: 5 loss 170.5006103515625\n",
            "progress: epoch: 6 loss 155.28952026367188\n",
            "progress: epoch: 7 loss 141.44383239746094\n",
            "progress: epoch: 8 loss 128.84031677246094\n",
            "progress: epoch: 9 loss 117.36698913574219\n",
            "progress: epoch: 10 loss 106.92195129394531\n",
            "progress: epoch: 11 loss 97.41255187988281\n",
            "progress: epoch: 12 loss 88.75453186035156\n",
            "progress: epoch: 13 loss 80.87122344970703\n",
            "progress: epoch: 14 loss 73.69293212890625\n",
            "progress: epoch: 15 loss 67.15625\n",
            "progress: epoch: 16 loss 61.20348358154297\n",
            "progress: epoch: 17 loss 55.782161712646484\n",
            "progress: epoch: 18 loss 50.84455871582031\n",
            "progress: epoch: 19 loss 46.34724426269531\n",
            "progress: epoch: 20 loss 42.25072479248047\n",
            "progress: epoch: 21 loss 38.519046783447266\n",
            "progress: epoch: 22 loss 35.119510650634766\n",
            "progress: epoch: 23 loss 32.022361755371094\n",
            "progress: epoch: 24 loss 29.20052146911621\n",
            "progress: epoch: 25 loss 26.62935447692871\n",
            "progress: epoch: 26 loss 24.286447525024414\n",
            "progress: epoch: 27 loss 22.151384353637695\n",
            "progress: epoch: 28 loss 20.205604553222656\n",
            "progress: epoch: 29 loss 18.43220329284668\n",
            "progress: epoch: 30 loss 16.815799713134766\n",
            "progress: epoch: 31 loss 15.342390060424805\n",
            "progress: epoch: 32 loss 13.999224662780762\n",
            "progress: epoch: 33 loss 12.774713516235352\n",
            "progress: epoch: 34 loss 11.658289909362793\n",
            "progress: epoch: 35 loss 10.640338897705078\n",
            "progress: epoch: 36 loss 9.712099075317383\n",
            "progress: epoch: 37 loss 8.865604400634766\n",
            "progress: epoch: 38 loss 8.093600273132324\n",
            "progress: epoch: 39 loss 7.3894758224487305\n",
            "progress: epoch: 40 loss 6.7472124099731445\n",
            "progress: epoch: 41 loss 6.16132926940918\n",
            "progress: epoch: 42 loss 5.626835823059082\n",
            "progress: epoch: 43 loss 5.1391825675964355\n",
            "progress: epoch: 44 loss 4.69422721862793\n",
            "progress: epoch: 45 loss 4.288200855255127\n",
            "progress: epoch: 46 loss 3.917661666870117\n",
            "progress: epoch: 47 loss 3.5794854164123535\n",
            "progress: epoch: 48 loss 3.2708141803741455\n",
            "progress: epoch: 49 loss 2.989051342010498\n",
            "progress: epoch: 50 loss 2.7318272590637207\n",
            "progress: epoch: 51 loss 2.49698543548584\n",
            "progress: epoch: 52 loss 2.2825608253479004\n",
            "progress: epoch: 53 loss 2.0867576599121094\n",
            "progress: epoch: 54 loss 1.907943844795227\n",
            "progress: epoch: 55 loss 1.7446311712265015\n",
            "progress: epoch: 56 loss 1.595460057258606\n",
            "progress: epoch: 57 loss 1.4591963291168213\n",
            "progress: epoch: 58 loss 1.334707260131836\n",
            "progress: epoch: 59 loss 1.2209659814834595\n",
            "progress: epoch: 60 loss 1.1170368194580078\n",
            "progress: epoch: 61 loss 1.0220613479614258\n",
            "progress: epoch: 62 loss 0.9352616667747498\n",
            "progress: epoch: 63 loss 0.8559253811836243\n",
            "progress: epoch: 64 loss 0.7834022045135498\n",
            "progress: epoch: 65 loss 0.7171016335487366\n",
            "progress: epoch: 66 loss 0.6564835906028748\n",
            "progress: epoch: 67 loss 0.6010559797286987\n",
            "progress: epoch: 68 loss 0.5503686666488647\n",
            "progress: epoch: 69 loss 0.5040119886398315\n",
            "progress: epoch: 70 loss 0.4616098403930664\n",
            "progress: epoch: 71 loss 0.4228226840496063\n",
            "progress: epoch: 72 loss 0.3873378336429596\n",
            "progress: epoch: 73 loss 0.35487017035484314\n",
            "progress: epoch: 74 loss 0.32516127824783325\n",
            "progress: epoch: 75 loss 0.29797255992889404\n",
            "progress: epoch: 76 loss 0.2730875313282013\n",
            "progress: epoch: 77 loss 0.2503098249435425\n",
            "progress: epoch: 78 loss 0.22945834696292877\n",
            "progress: epoch: 79 loss 0.21036779880523682\n",
            "progress: epoch: 80 loss 0.19288739562034607\n",
            "progress: epoch: 81 loss 0.17687970399856567\n",
            "progress: epoch: 82 loss 0.162218376994133\n",
            "progress: epoch: 83 loss 0.14879010617733002\n",
            "progress: epoch: 84 loss 0.13648828864097595\n",
            "progress: epoch: 85 loss 0.12521815299987793\n",
            "progress: epoch: 86 loss 0.11489146947860718\n",
            "progress: epoch: 87 loss 0.10542887449264526\n",
            "progress: epoch: 88 loss 0.09675690531730652\n",
            "progress: epoch: 89 loss 0.08880859613418579\n",
            "progress: epoch: 90 loss 0.08152198791503906\n",
            "progress: epoch: 91 loss 0.07484234869480133\n",
            "progress: epoch: 92 loss 0.06871755421161652\n",
            "progress: epoch: 93 loss 0.06310124695301056\n",
            "progress: epoch: 94 loss 0.05795057862997055\n",
            "progress: epoch: 95 loss 0.0532262809574604\n",
            "progress: epoch: 96 loss 0.04889268800616264\n",
            "progress: epoch: 97 loss 0.044916994869709015\n",
            "progress: epoch: 98 loss 0.041269492357969284\n",
            "progress: epoch: 99 loss 0.037922170013189316\n",
            "estimation of the parameters:\n",
            "Parameter containing:\n",
            "tensor([[ 2.0010, -2.9641]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.9794], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0tJqi0yVHfW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}